{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット自体の再配布は禁止なので、Gitコミット時に出力を消す\n",
    "def no_redistribution(data):\n",
    "    pass\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習コードの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_tsv_path):\n",
    "    df = df = pandas.read_table(dataset_tsv_path)\n",
    "    df = df.dropna(subset=['label'])\n",
    "    print('length: ', len(df))\n",
    "    return df['text'].values, df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  4125\n"
     ]
    }
   ],
   "source": [
    "no_redistribution(load_dataset('/app/data/purin.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今日', 'の', 'ご飯', 'は', '焼肉', 'です']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "def tokenize(text):\n",
    "    return t.tokenize(text, wakati=True)\n",
    "\n",
    "list(tokenize(\"今日のご飯は焼肉です\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import count_nonzero\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, x_train, y_train, x_test, y_test,\n",
    "        lowercase=False, tokenize=None, preprocessor=None) -> None:\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.vectorizer = CountVectorizer(\n",
    "            lowercase=lowercase,\n",
    "            tokenizer=tokenize,\n",
    "            preprocessor=preprocessor)\n",
    "\n",
    "    def train(self):\n",
    "        x_train_vec = self.vectorizer.fit_transform(self.x_train)\n",
    "        # 不均衡データセットなので重みをつける\n",
    "        weights = {\n",
    "            0: 1 / count_nonzero(y_train == 0),\n",
    "            1: 1 / count_nonzero(y_train == 1),\n",
    "        }\n",
    "        self.model = LogisticRegression(solver='liblinear', class_weight=weights)\n",
    "        self.model.fit(x_train_vec, self.y_train)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, x, proba = True):\n",
    "        x_vec = self.vectorizer.transform(x)\n",
    "        if proba:\n",
    "            predictor = self.model.predict_proba\n",
    "        else:\n",
    "            predictor = self.model.predict\n",
    "        return predictor(x_vec)\n",
    "\n",
    "    def eval_and_print(self):\n",
    "        y_pred = self.predict(self.x_test, proba=False)\n",
    "        print('roc_auc_score (macro average)', roc_auc_score(self.y_test, y_pred, average='macro'))\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_test, y_pred).ravel()\n",
    "        print('tn, fp, fn, tp', tn, fp, fn, tp)\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "    \n",
    "    def trailn_and_eval(self):\n",
    "        self.train()\n",
    "        self.eval_and_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  4125\n"
     ]
    }
   ],
   "source": [
    "x, y = load_dataset('/app/data/purin.tsv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "trainer = Trainer(x_train, y_train, x_test, y_test, tokenize=tokenize)\n",
    "\n",
    "model = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score (macro average) 0.7871838042049935\n",
      "tn, fp, fn, tp 54 10 205 556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.84      0.33        64\n",
      "           1       0.98      0.73      0.84       761\n",
      "\n",
      "    accuracy                           0.74       825\n",
      "   macro avg       0.60      0.79      0.59       825\n",
      "weighted avg       0.92      0.74      0.80       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.eval_and_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46503863, 0.53496137]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(['ポケモンのプリンとニャースとイーブイかわいい'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5058649, 0.4941351]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(['セブンのスイーツの焼きプリンおいしい'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score (macro average) 0.7871838042049935\n",
      "tn, fp, fn, tp 54 10 205 556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.84      0.33        64\n",
      "           1       0.98      0.73      0.84       761\n",
      "\n",
      "    accuracy                           0.74       825\n",
      "   macro avg       0.60      0.79      0.59       825\n",
      "weighted avg       0.92      0.74      0.80       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Trainer(x_train, y_train, x_test, y_test, tokenize=tokenize).trailn_and_eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score (macro average) 0.7977681504599212\n",
      "tn, fp, fn, tp 53 11 177 584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.83      0.36        64\n",
      "           1       0.98      0.77      0.86       761\n",
      "\n",
      "    accuracy                           0.77       825\n",
      "   macro avg       0.61      0.80      0.61       825\n",
      "weighted avg       0.92      0.77      0.82       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_anchor(text):\n",
    "    return re.sub(r'\\@[a-zA-Z0-9]+', '', text)\n",
    "\n",
    "Trainer(x_train, y_train, x_test, y_test, tokenize=tokenize, preprocessor=remove_anchor).trailn_and_eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "028baece2d5c9c450a926b56a2feb9be08d5da082e5e98dbd5d7f0ec42d420e8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('purin-nlp-9TtSrW0h-py3.10': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
